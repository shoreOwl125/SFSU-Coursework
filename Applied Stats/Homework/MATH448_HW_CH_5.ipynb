{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MATH 448  \n",
        "Homework CH 5  \n",
        "Andrew Dahlstrom  \n",
        "4/11/24  \n"
      ],
      "metadata": {
        "id": "DMQAqtDQZ2UJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)       \n",
        "a)  \n",
        "This cross validation technique splits the dataset randomly into k folds equally where k is an arbitrarily chosen integer. One of the folds becomes the validation set while the remaining folds are the training set. The model is trained and tested on the validation fold, the performance is measured. This process is repeated until all folds each serve as the validation set once. The performance results are then averaged across the k repetitions.    \n",
        "\n",
        "b)  \n",
        "I.  \n",
        "Advantages relative to the validation set approach include, k-fold uses all parts of the dataset in both training and testing through its process and this process can also reduce the variance compared to the validation set approach which is more dependent on which data was selected for the test or training sets. Disadvantages relative to the validation set approach include increased computational complexity by iterating the process though all k folds. Itâ€™s also not as simple to implement, you need to know a good value for k.  \n",
        "\n",
        "II.   \n",
        "Advantages relative to LOOCV (Leave one out) is that k-fold has a similar process to LOOCV but is less extreme since LOOCV repeats the process for the number of data observations rather than k times. This means k-fold is much less computationally intensive and also is less sensitive to outliers since an outlier could be the test observation of the LOOCV model. Disadvantages relative to LOOCV include a potentially higher bias because the larger test set (one fold vs one observation) means less training data. Also LOOCV is averaged over many more trials which could lead to a potentially lower variance than k-fold.\n"
      ],
      "metadata": {
        "id": "xrNNhFLZaC6M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IZl9iw6WZmHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0196d2cc-d95f-4b4b-bf59-185f4ef45caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  default student      balance        income\n",
            "0      No      No   729.526495  44361.625074\n",
            "1      No     Yes   817.180407  12106.134700\n",
            "2      No      No  1073.549164  31767.138947\n",
            "3      No      No   529.250605  35704.493935\n",
            "4      No      No   785.655883  38463.495879\n"
          ]
        }
      ],
      "source": [
        "# 5\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MATH 448/Default.csv')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Convert the response to numerical\n",
        "df['default'] = df['default'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Predictor variables\n",
        "X = df[['income', 'balance']]\n",
        "# Response variable\n",
        "y = df['default']\n",
        "model_train = LogisticRegression(solver='liblinear')"
      ],
      "metadata": {
        "id": "wGwkmt5jcSRr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b)\n",
        "# Ensure reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Split the dataset into training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "zBvwiPbWemNm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Fit logistic regression model on training data\n",
        "model_train.fit(X_train, y_train)\n",
        "\n",
        "# Obtain class predictions\n",
        "predictions_class = model_train.predict(X_val)\n",
        "print(predictions_class[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoxgkcIohZct",
        "outputId": "1d9b6faf-dcdd-4133-e480-b7a47a9f7cf8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the validation set error\n",
        "val_error = 1 - accuracy_score(y_val, predictions_class)\n",
        "print(f'Validation set error: {val_error}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKXFcLMmdue1",
        "outputId": "ef05cec5-47bf-4fd1-e2f5-95b11ebf95e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set error: 0.03700000000000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c)\n",
        "for i in range(1, 4):\n",
        "\n",
        "  # Split the dataset into training and validation\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=i)\n",
        "  # Fit logistic regression model on training data\n",
        "  model_train.fit(X_train, y_train)\n",
        "\n",
        "  # Obtain class predictions\n",
        "  predictions_class = model_train.predict(X_val)\n",
        "\n",
        "  # Compute the validation set error\n",
        "  val_error = 1 - accuracy_score(y_val, predictions_class)\n",
        "  print(f'Validation set error: {val_error}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMXth0Gtj5OK",
        "outputId": "82ba4213-00a0-47d8-a8ee-7bc6badf9a5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set error: 0.02949999999999997\n",
            "Validation set error: 0.02849999999999997\n",
            "Validation set error: 0.030000000000000027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are all very similar with a correct prediction on validation set of about 97% correct."
      ],
      "metadata": {
        "id": "8LQHhH3sk370"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# d)\n",
        "# Create dummy variable for student\n",
        "df['student'] = df['student'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Add student to the predictors\n",
        "X = df[['income', 'balance', 'student']]\n",
        "# Response variable\n",
        "y = df['default']\n",
        "\n",
        "# Split the dataset into training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Fit logistic regression model on training data\n",
        "model_train.fit(X_train, y_train)\n",
        "\n",
        "# Obtain class predictions\n",
        "predictions_class = model_train.predict(X_val)\n",
        "\n",
        "# Compute the validation set error\n",
        "val_error = 1 - accuracy_score(y_val, predictions_class)\n",
        "print(f'Validation set error: {val_error}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31e4meO9lTXs",
        "outputId": "dbb456b9-9115-477d-9a91-2cc2a37c0da8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set error: 0.03700000000000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the student feature as a predictor did not lead to a reduction in the test error rate."
      ],
      "metadata": {
        "id": "EjnQfqwwmGmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6)\n",
        "# Set predictors and intercept for sm models\n",
        "X = sm.add_constant(df[['income', 'balance']])\n",
        "# Set response\n",
        "y = df['default']\n",
        "\n",
        "# a)\n",
        "# Fit the model using GLM\n",
        "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
        "results = model.fit()\n",
        "\n",
        "# Determine estimated standard errors using summary\n",
        "results.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "hsIY-uL5tafJ",
        "outputId": "ef2714cf-9a21-4ec4-c57b-ecef46528cff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                 Generalized Linear Model Regression Results                  \n",
              "==============================================================================\n",
              "Dep. Variable:                default   No. Observations:                10000\n",
              "Model:                            GLM   Df Residuals:                     9997\n",
              "Model Family:                Binomial   Df Model:                            2\n",
              "Link Function:                  Logit   Scale:                          1.0000\n",
              "Method:                          IRLS   Log-Likelihood:                -789.48\n",
              "Date:                Fri, 12 Apr 2024   Deviance:                       1579.0\n",
              "Time:                        05:49:49   Pearson chi2:                 6.95e+03\n",
              "No. Iterations:                     9   Pseudo R-squ. (CS):             0.1256\n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const        -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
              "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
              "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
              "==============================================================================\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Generalized Linear Model Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>default</td>     <th>  No. Observations:  </th>  <td> 10000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  9997</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -789.48</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Fri, 12 Apr 2024</td> <th>  Deviance:          </th> <td>  1579.0</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>05:49:49</td>     <th>  Pearson chi2:      </th> <td>6.95e+03</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Iterations:</th>          <td>9</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.1256</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>   <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>income</th>  <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>balance</th> <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}   &     default      & \\textbf{  No. Observations:  } &    10000    \\\\\n\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &     9997    \\\\\n\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &        2    \\\\\n\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -789.48   \\\\\n\\textbf{Date:}            & Fri, 12 Apr 2024 & \\textbf{  Deviance:          } &    1579.0   \\\\\n\\textbf{Time:}            &     05:49:49     & \\textbf{  Pearson chi2:      } &  6.95e+03   \\\\\n\\textbf{No. Iterations:}  &        9         & \\textbf{  Pseudo R-squ. (CS):} &   0.1256    \\\\\n\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                 & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}   &     -11.5405  &        0.435     &   -26.544  &         0.000        &      -12.393    &      -10.688     \\\\\n\\textbf{income}  &    2.081e-05  &     4.99e-06     &     4.174  &         0.000        &      1.1e-05    &     3.06e-05     \\\\\n\\textbf{balance} &       0.0056  &        0.000     &    24.835  &         0.000        &        0.005    &        0.006     \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Generalized Linear Model Regression Results}\n\\end{center}"
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b\n",
        "# Takes as input data and index of the observations, and outputs\n",
        "# the coefficient estimates for income and balance\n",
        "def boot_fn(data, index):\n",
        "    X = sm.add_constant(data.loc[index, ['income', 'balance']])\n",
        "    y = data.loc[index, 'default']\n",
        "    model = sm.GLM(y, X, family=sm.families.Binomial()).fit()\n",
        "    return model.params[1:]"
      ],
      "metadata": {
        "id": "WFFaRnVmxFrG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c\n",
        "# Define # of bootstraps\n",
        "bootstraps = 100\n",
        "# Coefficients for predictors income and balance\n",
        "coeffs = np.zeros((bootstraps, 2))\n",
        "\n",
        "for i in range(bootstraps):\n",
        "    # Generate random indices\n",
        "    indices = np.random.choice(df.index, size=len(df), replace=True)\n",
        "    # Get the bootstrap coefficients\n",
        "    boot_coeffs = boot_fn(df, indices)\n",
        "    # Store income and balance coefficients\n",
        "    coeffs[i,:] = boot_coeffs\n",
        "\n",
        "# Calculate the standard errors of the coefficients\n",
        "boot_se = np.std(coeffs, axis=0)\n",
        "print(f\"Bootstrap SE for Income = {boot_se[0]}, for Balance = {boot_se[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdvVlhOSxjwZ",
        "outputId": "f521f5a2-7ee8-4e08-dc64-a0638cc3b316"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap SE for Income = 4.833950265363818e-06, for Balance = 0.0002557994432092796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d)  \n",
        "In both approaches the estimated standard errors obtained using sm.GLM() and bootstrap are very low. The coefficient error for Income is slightly higher using the GLM and the Balance coefficient SE is higher using bootstrap with 100 interations."
      ],
      "metadata": {
        "id": "0_y5PRMa1lDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7)\n",
        "weekly = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MATH 448/Weekly.csv')\n",
        "print(weekly.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCvkAd-62pLX",
        "outputId": "1f37f31a-9eb0-4db2-82f1-aa708fba9522"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
            "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
            "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
            "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
            "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
            "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a\n",
        "weekly['Direction'] = weekly['Direction'].apply(lambda x: 1 if x == 'Up' else 0)\n",
        "X = sm.add_constant(weekly[['Lag1', 'Lag2']])\n",
        "y = weekly['Direction']\n",
        "\n",
        "# Fit the logistic regression model\n",
        "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ngmDToG3lry",
        "outputId": "3d37947a-5a25-4d7e-dbd7-1a8d576379f3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:              Direction   No. Observations:                 1089\n",
            "Model:                            GLM   Df Residuals:                     1086\n",
            "Model Family:                Binomial   Df Model:                            2\n",
            "Link Function:                  Logit   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -744.11\n",
            "Date:                Fri, 12 Apr 2024   Deviance:                       1488.2\n",
            "Time:                        05:55:14   Pearson chi2:                 1.09e+03\n",
            "No. Iterations:                     4   Pseudo R-squ. (CS):           0.007303\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.2212      0.061      3.599      0.000       0.101       0.342\n",
            "Lag1          -0.0387      0.026     -1.477      0.140      -0.090       0.013\n",
            "Lag2           0.0602      0.027      2.270      0.023       0.008       0.112\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b\n",
        "# Using all data bit first observation in training set\n",
        "X_train = X.iloc[1:]\n",
        "y_train = y.iloc[1:]\n",
        "\n",
        "model_LOO = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
        "results_LOO = model_LOO.fit()"
      ],
      "metadata": {
        "id": "kJ3M-_mG3-MK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c\n",
        "# Predict the direction of the first observation\n",
        "pred_prob = results_LOO.predict(X.iloc[0:1])\n",
        "pred_prob_value = pred_prob.values[0]\n",
        "pred = 0\n",
        "if pred_prob_value > 0.5:\n",
        "  pred = 1\n",
        "else:\n",
        "  pred = 0\n",
        "\n",
        "classification = pred == y.iloc[0]\n",
        "print(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sW7xqrQ4qS4",
        "outputId": "794e3ab3-da8c-411e-d430-b91251b0637a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first observation was not correctly classified."
      ],
      "metadata": {
        "id": "mc7b1c7n6t72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# d\n",
        "# Create list to store results\n",
        "results = []\n",
        "\n",
        "for i in range(len(weekly)):\n",
        "    # Leave out the ith observation\n",
        "    X_train = X.drop(X.index[i])\n",
        "    y_train = y.drop(y.index[i])\n",
        "    X_test = X.iloc[i:i+1]\n",
        "\n",
        "    # Fit the GLM\n",
        "    model_LOO = sm.GLM(y_train, X_train, family=sm.families.Binomial()).fit()\n",
        "\n",
        "    # Predict the ith observation\n",
        "    ith_pred_prob = model_LOO.predict(X_test)\n",
        "    ith_pred_value = ith_pred_prob.values[0]\n",
        "\n",
        "    # Determine the predicted class based on the probability\n",
        "    if ith_pred_value > 0.5:\n",
        "        ith_pred = 1\n",
        "    else:\n",
        "        ith_pred = 0\n",
        "\n",
        "    # Check if the prediction was correct 1 represents error\n",
        "    actual_value = y.iloc[i]\n",
        "    if ith_pred == actual_value:\n",
        "        error = 0\n",
        "    else:\n",
        "        error = 1\n",
        "\n",
        "    # Append the error value to results\n",
        "    results.append(error)\n",
        "\n",
        "print(results[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yQ9ag5a61Ve",
        "outputId": "f59bd93d-0c66-48f5-ec5d-b5519e010e84"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# e\n",
        "# Compute LOO error\n",
        "Avg_loo_error = np.mean(results)\n",
        "print(Avg_loo_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQWGZVBR7R0w",
        "outputId": "466bf190-c07e-4066-ac6a-e3c8e49886bf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44995408631772266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results appear to be poor. The averaged test error over the dataset for LOOCV is .45 which indicates that it has approximately 50% chance of being correct for a binary classification."
      ],
      "metadata": {
        "id": "BAj5tL3n_xp4"
      }
    }
  ]
}