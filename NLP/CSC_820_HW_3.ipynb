{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CSC 820 Homework 3  \nAndrew Dahlstrom  \n2/21/2024","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import gutenberg\nimport pandas as pd\nimport Levenshtein \n\n# Load Lewis Carroll's Alice in Wonderland from project Gutenberg library into a list like object\ncorpus = gutenberg.words('carroll-alice.txt') \ncorpus_name = \"Alice in Wonderland\"\n# Use the built-in set method to automatically create a leist of unique words from the corpus\ntypes = set(corpus)\n\n# Total number of words (tokens) in corpus\nN = len(corpus)\n\n# Create a dataframe to hold the types from the corpus\ncorpus_table = pd.DataFrame(types, columns=['word'])\ncorpus_table.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T06:57:19.140028Z","iopub.execute_input":"2024-02-22T06:57:19.140376Z","iopub.status.idle":"2024-02-22T06:57:22.581289Z","shell.execute_reply.started":"2024-02-22T06:57:19.140347Z","shell.execute_reply":"2024-02-22T06:57:22.579944Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"        word\n0   squeaked\n1    already\n2  cupboards\n3   laughing\n4    against","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>squeaked</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>already</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cupboards</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>laughing</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>against</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create a dataframe to store all the tokens from the corpus in a column\ntoken_table = pd.DataFrame(corpus, columns=['word'])\n\n# Create a series to hold the frequency counts of each word from the token dataframe\nword_freq = token_table['word'].value_counts()\n\n# Map the word frequency to the corresponding word in the type table under\n# the new frequency column\ncorpus_table['frequency'] = corpus_table['word'].map(word_freq)\n\n# Create a new column that contains the probability of the word occuring in the corpus\n# by dividing each word frequency by the total number of words in the corpus.\ncorpus_table['probability'] = corpus_table['frequency'] / N\n\ncorpus_table.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T06:57:22.583077Z","iopub.execute_input":"2024-02-22T06:57:22.583514Z","iopub.status.idle":"2024-02-22T06:57:22.655414Z","shell.execute_reply.started":"2024-02-22T06:57:22.583486Z","shell.execute_reply":"2024-02-22T06:57:22.654274Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"        word  frequency  probability\n0   squeaked          1     0.000029\n1    already          2     0.000059\n2  cupboards          2     0.000059\n3   laughing          1     0.000029\n4    against          9     0.000264","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>frequency</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>squeaked</td>\n      <td>1</td>\n      <td>0.000029</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>already</td>\n      <td>2</td>\n      <td>0.000059</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cupboards</td>\n      <td>2</td>\n      <td>0.000059</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>laughing</td>\n      <td>1</td>\n      <td>0.000029</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>against</td>\n      <td>9</td>\n      <td>0.000264</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Function declaration for word_search. Input is a word and checks corpus_table\n# for word, if found returns the corresponding probability of the word, else\n# returns word not found.\ndef word_search(word):\n    # result is a filtered dataframe returning only the row corresponding to word.\n    result = corpus_table[corpus_table['word'] == word]\n    \n    if result.empty:\n        closest_types = lev_distance(word, corpus_table)\n        #print(f\"The word '{word}' is not present in the corpus of '{corpus_name}'.\")\n        for index, row in closest_types.iterrows():\n            print(f\"Type: {row['word']}, Probability: {row['probability']}\")\n    else:\n        # Get only the corresponding probability value with iloc[0]\n        prob = result['probability'].iloc[0]\n        print(f\"'{word}' is a complete and correct word as per corpus '{corpus_name}', and its probability is '{prob}'.\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T06:57:22.657140Z","iopub.execute_input":"2024-02-22T06:57:22.657548Z","iopub.status.idle":"2024-02-22T06:57:22.664647Z","shell.execute_reply.started":"2024-02-22T06:57:22.657512Z","shell.execute_reply":"2024-02-22T06:57:22.663409Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Function declaration for lev_distance to calculate the Levenshtein distance using pythons built-in\n# Levenshtein distance algorithm. Input is a word and dataframe containing the corpus types, frequencies and probabilities.\n# Returns a dataframe containing the top 5 that are most similar to the input string as per the Levenshtein distance.\ndef lev_distance(word, corpus_table):\n    # Copy the corpus table into the result table and create a new column for Levenshtein distances filled with placeholders.\n    result_table = corpus_table.copy()\n    result_table['Lev_Distance'] = 0\n    \n    # Iterate through the word column of the result table calculating\n    # the Levenshtein distances between the input word and corpus words and\n    # update result table inplace.\n    for index, row in result_table.iterrows():\n        distance = Levenshtein.distance(word, row['word'])\n        result_table.at[index, 'Lev_Distance'] = distance\n    \n    # Sort dataframe by shortest distance \n    result_table.sort_values(by='Lev_Distance', ascending=True, inplace=True)\n    \n    # Return only the top five closest types from the corpus\n    result_table = result_table.head(5)\n    \n    return result_table","metadata":{"execution":{"iopub.status.busy":"2024-02-22T06:57:22.668667Z","iopub.execute_input":"2024-02-22T06:57:22.669065Z","iopub.status.idle":"2024-02-22T06:57:22.678392Z","shell.execute_reply.started":"2024-02-22T06:57:22.669033Z","shell.execute_reply":"2024-02-22T06:57:22.677308Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Initialize program in main\nif __name__== \"__main__\":\n    while True: \n        user_input = input(f\"Begin by entering a word to search for it in '{corpus_name}' or 'exit' to exit the program.\")\n        if user_input == 'exit':\n            break\n        word_search(user_input)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T06:57:22.680181Z","iopub.execute_input":"2024-02-22T06:57:22.680572Z","iopub.status.idle":"2024-02-22T06:59:18.902015Z","shell.execute_reply.started":"2024-02-22T06:57:22.680538Z","shell.execute_reply":"2024-02-22T06:59:18.901065Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. Alice\n"},{"name":"stdout","text":"'Alice' is a complete and correct word as per corpus 'Alice in Wonderland', and its probability is '0.011609498680738786'.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. rabbit\n"},{"name":"stdout","text":"'rabbit' is a complete and correct word as per corpus 'Alice in Wonderland', and its probability is '0.0001465845793022574'.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. cat\n"},{"name":"stdout","text":"'cat' is a complete and correct word as per corpus 'Alice in Wonderland', and its probability is '0.0003224860744649663'.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. time\n"},{"name":"stdout","text":"'time' is a complete and correct word as per corpus 'Alice in Wonderland', and its probability is '0.001993550278510701'.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. mad\n"},{"name":"stdout","text":"'mad' is a complete and correct word as per corpus 'Alice in Wonderland', and its probability is '0.00041043682204632074'.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. homework\n"},{"name":"stdout","text":"Type: somewhere, Probability: 5.8633831720902964e-05\nType: someone, Probability: 2.9316915860451482e-05\nType: home, Probability: 0.0001465845793022574\nType: memory, Probability: 2.9316915860451482e-05\nType: work, Probability: 0.00023453532688361186\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. pizza\n"},{"name":"stdout","text":"Type: pine, Probability: 2.9316915860451482e-05\nType: sizes, Probability: 2.9316915860451482e-05\nType: puzzle, Probability: 2.9316915860451482e-05\nType: pigs, Probability: 0.00017590149516270889\nType: size, Probability: 0.00038111990618586926\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. Italy\n"},{"name":"stdout","text":"Type: scaly, Probability: 2.9316915860451482e-05\nType: tale, Probability: 8.795074758135444e-05\nType: stalk, Probability: 2.9316915860451482e-05\nType: talk, Probability: 0.00041043682204632074\nType: stay, Probability: 0.0001465845793022574\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. imagination\n"},{"name":"stdout","text":"Type: invitation, Probability: 5.8633831720902964e-05\nType: explanation, Probability: 5.8633831720902964e-05\nType: Ambition, Probability: 2.9316915860451482e-05\nType: imagine, Probability: 2.9316915860451482e-05\nType: variations, Probability: 2.9316915860451482e-05\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Begin by entering a word to search for it in 'Alice in Wonderland' or 'exit' to exit the program. exit\n"}]},{"cell_type":"markdown","source":"# Summary\n\nThis program is designed to extract the types and tokens from a corpus, in this case Lewis Carroll's \"Alice in Wonderland\" then builds a dataframe containing the unique words (types) and frequency of their occurrence in the corpus in order to calculate the probability of the word occurring in the corpus. \n\nThe program prompts the user to input a word then the program checks if the word is in the corpus dataframe exactly as it is input. If so then it displays a message indicating it is in the corpus and the associated probability. If the word is not found in the corpus, a similarity measure is made using the Levenshtein distance calculation between the input word and all types from the corpus. The top five most similar (shortest distance) words are returned in a message with their corresponding probabilities. \n\nImprovements to the program could include using word normalization to fix minor discrepancies such as upper case, punctuation or even more advanced techniques such as stemming and lemmatization. Another improvement could be optimizing the Levenshtein distance calculation, as iterating over the dataframe for each comparison is computationally expensive. \n\nThe most challenging part of the program is the lev_distance function which is where I encountered the most problems. Remembering how to iterate through the rows and columns of a dataframe and update column values inplace required a bit of research. Also understanding the data types returned by the NLTK methods and Levenshtein distance method required a bit of research as well.  The pairwise distance calculation was also confusing and required a bit of trial and error.\n\n","metadata":{}}]}